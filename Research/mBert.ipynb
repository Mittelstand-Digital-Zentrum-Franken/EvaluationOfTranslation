{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mBert\n",
    " = Multilingual Bidirectional Encoder Representations from Transformers\n",
    "\n",
    " mBERT ist ein mehrsprachiges Modell, das Texte in verschiedenen Sprachen verarbeiten kann, ohne sprachspezifische Modelle zu benötigen. Es misst die semantische Ähnlichkeit von Texten anhand von Embeddings, die Wörter in numerische Vektoren umwandeln. Diese Vektoren erfassen die Bedeutung der Wörter und ihre Beziehungen zueinander. Der Similarity Score basiert auf der Ähnlichkeit der Vektoren, unabhängig von der Sprache der Texte. So kann mBERT die semantische Ähnlichkeit zwischen Texten in verschiedenen Sprachen messen.\n",
    "\n",
    "### Vorteile:\n",
    "\n",
    "- Bidirektionales Encoding: Transformerencoder, Berücksichtigung des Kontext vor und nach einem Wort (Umfassendes Textverständnis)\n",
    "\n",
    "- Multilinguales Training: Lernen syntaktischer Strukturen, Semantik, Kontext auf verschiedenen Sprachen\n",
    "\n",
    "- Transferlernen: Modell ist für viele Sprachen geeignet, wodurch nicht für jede Sprache ein seperates Modell benötigt wird\n",
    "\n",
    "- Sprachverständnis auf Wortebene: Versteht Kontext jedes Wortes besser\n",
    "\n",
    "> Die Messung der Ergebnisse erfolgt durch den Similarity Score. Je höher dieser ist, desto ähnlicher sind sich die Texte.\n",
    "\n",
    "Quellen: \n",
    "- https://arxiv.org/pdf/1907.11692\n",
    "- https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sandra.nuissl\\Desktop\\EvaluationOfTranslation\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden des Modells und des Tokenizers (Es könnten hier auch andere Modelle herangezogen werden, je nach Fokus)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad der JSONS ermitteln\n",
    "folder = \"../Data/atticus\"\n",
    "list_files = os.listdir(folder)\n",
    "\n",
    "# Leere Liste für englische und deutsche Texte\n",
    "list_english_text = []\n",
    "list_german_text = []\n",
    "\n",
    "# Laden der Files und Extraktion der englischen Texte (Source Language = en-US)\n",
    "for path in list_files:\n",
    "    path_complete = folder + \"//\" + path\n",
    "    with open(path_complete,'r', encoding=\"utf-8-sig\") as file:\n",
    "        obj = json.load(file)\n",
    "\n",
    "    # Iterieren durch die Texte der JSON und Selection der englischen Texte\n",
    "    for text in obj:\n",
    "        # Selection der englischen Sätze\n",
    "        list_english_text.append(text['Text'])\n",
    "        # Überprüfen, ob die Sprache \"de-DE\" ist und Speichern in einer Liste\n",
    "        for translation in text['Translations']:\n",
    "            if translation['Language'] == 'de-DE':\n",
    "                list_german_text.append(translation['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellen der Datensätze\n",
    "source_sentence = list_english_text[20]\n",
    "translated_sentence = list_german_text[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize Sätze\n",
    "source_inputs = tokenizer(source_sentence, return_tensors='pt')\n",
    "translated_inputs = tokenizer(translated_sentence, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten embedding\n",
    "with torch.no_grad():\n",
    "    source_outputs = model(**source_inputs)\n",
    "    translated_outputs = model(**translated_inputs)\n",
    "\n",
    "# Anwendung des Embeddings\n",
    "source_embedding = source_outputs.last_hidden_state.mean(dim=1)\n",
    "translated_embedding = translated_outputs.last_hidden_state.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.5728966593742371\n"
     ]
    }
   ],
   "source": [
    "# Similarity Score kalkulieren\n",
    "similarity = cosine_similarity(source_embedding, translated_embedding)\n",
    "similarity_score = similarity.item()\n",
    "\n",
    "# Ausgabe\n",
    "print(f\"Similarity score: {similarity_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
